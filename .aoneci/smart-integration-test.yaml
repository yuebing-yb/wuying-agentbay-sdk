name: "Smart Integration Test"

params:
  test_type:
    name: Test Type
    type: string
    default: "all"
    options:
      - "all"
      - "python"
      - "typescript"
      - "golang"

jobs:
  smart-integration-test:
    name: "Smart Integration Test"
    runs-on:
      - "16-64Gi"
    image: alios-8u
    timeout: 3h
    retry:
      max: 2
      when:
        - runner_system_failure
        - stuck_or_timeout_failure
    steps:
      - uses: checkout
      
      - uses: setup-env
        inputs:
          python-version: '3.12'
          node-version: '18'
          npm-version: '10'
          npm-cache: true
          go-version: '1.24.3'
          go-mod-cache: true
          go-cache: true
          
      - id: run-smart-tests
        name: "Run Smart Tests"
        run: |
          echo "ğŸ”„ Installing dependencies for Smart Test Runner..."
          
          # Setup Golang dependencies if needed
          if [ "${{params.test_type}}" = "golang" ] || [ "${{params.test_type}}" = "all" ]; then
            echo "ğŸ¹ Setting up Golang environment..."
            # Configure Go environment (setup-env already installed Go)
            go env -w GOPROXY=https://goproxy.cn,direct
            go env -w GOSUMDB=sum.golang.google.cn
            go env -w GOTOOLCHAIN=local
            go version
            
            if [ -d "golang" ]; then
              cd golang
              go mod download
              # Install Playwright browsers for Golang tests
              echo "ğŸ­ Installing Playwright browsers for Golang..."
              go run github.com/playwright-community/playwright-go/cmd/playwright@latest install --with-deps
              cd ..
            fi
          fi
          
          # Setup TypeScript dependencies if needed  
          if [ "${{params.test_type}}" = "typescript" ] || [ "${{params.test_type}}" = "all" ]; then
            echo "ğŸ“œ Setting up TypeScript environment..."
            # Node.js and npm already installed by setup-env
            node --version
            npm --version
            
            if [ -d "typescript" ]; then
              cd typescript
              # Use npm ci like the working unit tests
              npm config set fetch-timeout 300000
              npm config set fetch-retry-mintimeout 20000
              npm config set fetch-retry-maxtimeout 120000
              npm ci --prefer-offline --no-audit
              
              # Verify ts-jest installation
              echo "ğŸ” Verifying ts-jest installation..."
              npm list ts-jest || echo "âš ï¸ ts-jest not found"
              
              # Install Playwright browsers for TypeScript tests
              echo "ğŸ­ Installing Playwright browsers for TypeScript..."
              npx playwright install --with-deps || echo "âš ï¸ Playwright install failed"
              cd ..
            fi
          fi
          
          # Setup Python environment (always needed for the test runner itself)
          python -m pip config set global.timeout 600
          python -m pip config set global.retries 5
          python -m pip install --upgrade pip
          
          # Install Python dependencies similar to unit test job
          pip install "darabonba-core>=1.0.0,<2.0.0" \
                      "alibabacloud-tea-openapi>=0.4.0rc3" \
                      "cryptography>=44.0.0" \
                      "httpx>=0.28.1" \
                      "alibabacloud-tea-util>=0.3.13" \
                      "python-dotenv>=1.0.0" \
                      "pydantic>=2.0" \
                      "playwright>=1.5.0" \
                      "loguru>=0.7.0"
          
          # Install test dependencies
          pip install pytest pytest-cov pytest-asyncio
          
          # Install AI dependencies
          pip install langchain-openai langgraph langchain-core
          
          echo "ğŸ”§ Setting up environment..."
          # Ensure we're in the correct working directory
          cd /aoneci/runner/work/source || exit 1
          echo "ğŸ“‚ Current working directory: $(pwd)"
          
          # Install SDK in editable mode with correct path
          if [ -d "python" ]; then
            pip install -e ./python/
            echo "âœ… Python SDK installed successfully"
          else
            echo "âŒ Python directory not found"
            ls -la
            exit 1
          fi
          
          # Set PYTHONPATH similar to unit test job
          export PYTHONPATH="${PYTHONPATH}:$(pwd)/python"
          export AGENTBAY_API_KEY="${{secrets.AGENTBAY_API_KEY}}"
          export DASHSCOPE_API_KEY="${{secrets.DASHSCOPE_API_KEY}}"
          
          echo "ğŸš€ Starting Smart Test Runner..."
          echo "Working directory: $(pwd)"
          echo "Python path: $PYTHONPATH"
          
          # Set up environment for test execution
          # Ensure we have the correct working directory
          cd /aoneci/runner/work/source || exit 1
          
          # Set Go environment variables if needed
          if [ "${{params.test_type}}" = "golang" ] || [ "${{params.test_type}}" = "all" ]; then
            export GOPROXY=https://goproxy.cn,direct
            export GOSUMDB=sum.golang.google.cn  
            export GOTOOLCHAIN=local
            echo "ğŸ” Checking Go installation..."
            which go || echo "âŒ Go not found in PATH"
            go version || echo "âŒ Go version check failed"
          fi
          
          if [ "${{params.test_type}}" = "typescript" ] || [ "${{params.test_type}}" = "all" ]; then
            echo "ğŸ” Checking Node.js installation..."
            which node || echo "âŒ Node not found in PATH"
            node --version || echo "âŒ Node version check failed"
            which npm || echo "âŒ npm not found in PATH"
            npm --version || echo "âŒ npm version check failed"
          fi
          
          # Run the smart test runner
          if python scripts/smart_test_runner.py --test-type="${{params.test_type}}"; then
            echo "âœ… Smart Test Runner completed successfully"
            
            # Check if test report was generated
          if [ -f "test_report.md" ]; then
            echo "âœ… Test report generated successfully"
            
            # Display in CI Summary (Markdown format)
            echo "## ğŸ¤– Smart Integration Test Report" >> $AONE_CI_SUMMARY_MD
            echo "" >> $AONE_CI_SUMMARY_MD
            cat test_report.md >> $AONE_CI_SUMMARY_MD
            
            # Archive as build artifacts
            mkdir -p artifacts
            cp test_report.md artifacts/smart_test_report.md
          else
            echo "âš ï¸ No test report generated"
            echo "## âŒ Smart Integration Test Report" >> $AONE_CI_SUMMARY_MD
            echo "No test report was generated. Check the logs above for errors." >> $AONE_CI_SUMMARY_MD
          fi
          else
            echo "âŒ Smart Test Runner failed with exit code $?"
            echo "âŒ CI pipeline will now fail"
            exit 1
          fi
          
      - id: display-test-results
        name: "Display Test Results"
        run: |
          if [ -f "test_report.md" ]; then
            echo "ğŸ“‹ å¤±è´¥æµ‹è¯•æ¦‚è§ˆï¼š"
            echo ""
            
            # Extract and show failed test titles first
            if grep -q "âŒ å¤±è´¥æµ‹è¯•" test_report.md; then
              # Extract all failed test IDs and show them with proper formatting
              awk '
              BEGIN { 
                test_count = 0;
              }
              /## âŒ å¤±è´¥æµ‹è¯•/ {
                test_count++;
                # Skip empty lines and find the test ID line
                while (getline > 0) {
                  if (/^\*\*æµ‹è¯•ID\*\*:/) {
                    # Extract test ID from **æµ‹è¯•ID**: `test_id_here`
                    gsub(/^\*\*æµ‹è¯•ID\*\*: `/, "", $0);
                    gsub(/`$/, "", $0);
                    print "### " test_count ". " $0;
                    print "";
                    break;
                  }
                }
                next;
              }
              ' test_report.md
              
              echo ""
              echo "::group::ğŸ” æŸ¥çœ‹å®Œæ•´æµ‹è¯•è¯¦æƒ…å’ŒAIåˆ†æ"
              echo "åŒ…å«æ‰€æœ‰å¤±è´¥æµ‹è¯•çš„è¯¦ç»†ä¿¡æ¯ã€AIåˆ†æå’Œä¿®å¤å»ºè®®ï¼š"
              echo ""
              cat test_report.md
              echo "::endgroup::"
              
            else
              echo "âœ… æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼"
            fi
            
            # Show success summary from the summary line
            if grep -q "Tests |" test_report.md; then
              SUMMARY_LINE=$(grep "Tests |" test_report.md | head -1)
              echo ""
              echo "ğŸ“Š $SUMMARY_LINE"
            fi
          else
            echo "âš ï¸ æµ‹è¯•æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨"
          fi

