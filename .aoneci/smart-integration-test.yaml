name: "Smart Integration Test"

params:
  test_type:
    name: Test Type
    type: string
    default: "all"
    options:
      - "all"
      - "python"
      - "typescript"
      - "golang"

traits:
  - type: notification
    properties:
      types: dingtalk
      when: all
      users: 187788
      content: |
        ---
        - **Test Date**: ${{git.commitDate}}
        - **Test Report**
            - @${{git.repo}}
            - **Branch**: ${{git.branch}}
            - **Commit**: ${{git.shortSha}}
            - **Changed By**: ${{git.employeeId}}
                      
        | ğŸ”– | Test Result |
        | :-: | :-: |
        | ğŸ§ª | ${{jobs.smart-integration-test.name}} |
        ${{jobs.smart-integration-test.outputs.failed_test_table}}

jobs:
  smart-integration-test:
    name: "Smart Integration Test"
    runs-on:
      - "4-16Gi"
    image: alios-8u
    timeout: 5h
    retry:
      max: 2
      when:
        - runner_system_failure
        - stuck_or_timeout_failure
    steps:
      - uses: checkout
      
      - uses: setup-env
        inputs:
          python-version: '3.12'
          node-version: '18'
          npm-version: '10'
          npm-cache: true
          go-version: '1.24.3'
          go-mod-cache: true
          go-cache: true
          
      - id: run-smart-tests
        name: "Run Smart Tests"
        run: |
          echo "ğŸ”„ Installing dependencies for Smart Test Runner..."
          
          # Setup Golang dependencies if needed
          if [ "${{params.test_type}}" = "golang" ] || [ "${{params.test_type}}" = "all" ]; then
            echo "ğŸ¹ Setting up Golang environment..."
            # Configure Go environment (setup-env already installed Go)
            go env -w GOPROXY=https://goproxy.cn,direct
            go env -w GOSUMDB=sum.golang.google.cn
            go env -w GOTOOLCHAIN=local
            go version
            
            if [ -d "golang" ]; then
              cd golang
              go mod download
              # Install Playwright browsers for Golang tests
              echo "ğŸ­ Installing Playwright browsers for Golang..."
              go run github.com/playwright-community/playwright-go/cmd/playwright@latest install --with-deps
              cd ..
            fi
          fi
          
          # Setup TypeScript dependencies if needed  
          if [ "${{params.test_type}}" = "typescript" ] || [ "${{params.test_type}}" = "all" ]; then
            echo "ğŸ“œ Setting up TypeScript environment..."
            # Node.js and npm already installed by setup-env
            node --version
            npm --version
            
            if [ -d "typescript" ]; then
              cd typescript
              # Use npm ci like the working unit tests
              npm config set fetch-timeout 300000
              npm config set fetch-retry-mintimeout 20000
              npm config set fetch-retry-maxtimeout 120000
              npm ci --prefer-offline --no-audit
              
              # Verify ts-jest installation
              echo "ğŸ” Verifying ts-jest installation..."
              npm list ts-jest || echo "âš ï¸ ts-jest not found"
              
              # Install Playwright browsers for TypeScript tests
              echo "ğŸ­ Installing Playwright browsers for TypeScript..."
              npx playwright install --with-deps || echo "âš ï¸ Playwright install failed"
              cd ..
            fi
          fi
          
          # Setup Python environment (always needed for the test runner itself)
          python -m pip config set global.timeout 600
          python -m pip config set global.retries 5
          python -m pip install --upgrade pip
          
          # Install Python dependencies similar to unit test job
          pip install "darabonba-core>=1.0.0,<2.0.0" \
                      "alibabacloud-tea-openapi>=0.4.0rc3" \
                      "cryptography>=44.0.0" \
                      "httpx>=0.28.1" \
                      "alibabacloud-tea-util>=0.3.13" \
                      "python-dotenv>=1.0.0" \
                      "pydantic>=2.0" \
                      "playwright>=1.5.0" \
                      "loguru>=0.7.0"
          
          # Install test dependencies
          pip install pytest pytest-cov pytest-asyncio
          
          # Install AI dependencies
          pip install langchain-openai langgraph langchain-core
          
          echo "ğŸ”§ Setting up environment..."
          # Ensure we're in the correct working directory
          cd /aoneci/runner/work/source || exit 1
          echo "ğŸ“‚ Current working directory: $(pwd)"
          
          # Install SDK in editable mode with correct path
          if [ -d "python" ]; then
            pip install -e ./python/
            echo "âœ… Python SDK installed successfully"
          else
            echo "âŒ Python directory not found"
            ls -la
            exit 1
          fi
          
          # Set PYTHONPATH similar to unit test job
          export PYTHONPATH="${PYTHONPATH}:$(pwd)/python"
          export AGENTBAY_API_KEY="${{secrets.AGENTBAY_API_KEY}}"
          export DASHSCOPE_API_KEY="${{secrets.DASHSCOPE_API_KEY}}"
          
          echo "ğŸš€ Starting Smart Test Runner..."
          echo "Working directory: $(pwd)"
          echo "Python path: $PYTHONPATH"
          
          # Set up environment for test execution
          # Ensure we have the correct working directory
          cd /aoneci/runner/work/source || exit 1
          
          # Set Go environment variables if needed
          if [ "${{params.test_type}}" = "golang" ] || [ "${{params.test_type}}" = "all" ]; then
            export GOPROXY=https://goproxy.cn,direct
            export GOSUMDB=sum.golang.google.cn  
            export GOTOOLCHAIN=local
            echo "ğŸ” Checking Go installation..."
            which go || echo "âŒ Go not found in PATH"
            go version || echo "âŒ Go version check failed"
          fi
          
          if [ "${{params.test_type}}" = "typescript" ] || [ "${{params.test_type}}" = "all" ]; then
            echo "ğŸ” Checking Node.js installation..."
            which node || echo "âŒ Node not found in PATH"
            node --version || echo "âŒ Node version check failed"
            which npm || echo "âŒ npm not found in PATH"
            npm --version || echo "âŒ npm version check failed"
          fi
          
          # Run the smart test runner
          if python scripts/smart_test_runner.py --test-type="${{params.test_type}}"; then
            echo "âœ… Smart Test Runner completed successfully"
            
            # Check if test report was generated
          if [ -f "test_report.md" ]; then
            echo "âœ… Test report generated successfully"
            
            # Display in CI Summary using è±†è…å— format
            # Extract test statistics
            TOTAL_TESTS=$(grep -o "[0-9]\+ Tests" test_report.md | grep -o "[0-9]\+" || echo "0")
            PASSED_TESTS=$(grep -o "âœ… [0-9]\+ Passed" test_report.md | grep -o "[0-9]\+" || echo "0")
            FAILED_TESTS=$(grep -o "âŒ [0-9]\+ Failed" test_report.md | grep -o "[0-9]\+" || echo "0")
            
            # Generate TEST_CASE è±†è…å— - ensure all required fields are present
            SKIPPED_TESTS=0  # Default to 0 if no skipped tests
            TEST_CASE_JSON="{\"name\": \"æ™ºèƒ½é›†æˆæµ‹è¯•\", \"failed\": $FAILED_TESTS, \"skipped\": $SKIPPED_TESTS, \"passed\": $PASSED_TESTS}"
            echo "TEST_CASE=$TEST_CASE_JSON" >> $AONE_CI_SUMMARY
            
            # Extract failed test IDs for notification table format
            FAILED_TEST_TABLE=""
            if [ "$FAILED_TESTS" -gt 0 ]; then
              FAILED_TEST_TABLE=$(grep -A1 "âŒ å¤±è´¥æµ‹è¯•" test_report.md | grep "æµ‹è¯•ID:" | sed 's/æµ‹è¯•ID: //' | while read test_id; do
                echo "| âŒ | $test_id |"
              done)
            fi
            echo "failed_test_table<<EOF" >> $AONE_CI_JOB_OUTPUTS
            echo "$FAILED_TEST_TABLE" >> $AONE_CI_JOB_OUTPUTS
            echo "EOF" >> $AONE_CI_JOB_OUTPUTS
            
            # If there are failures, also add detailed results to Markdown summary
            if [ "$FAILED_TESTS" -gt 0 ]; then
              # Also show detailed results in markdown format for failed tests
              echo "## ğŸ¤– Smart Integration Test Report" >> $AONE_CI_SUMMARY_MD
              echo "" >> $AONE_CI_SUMMARY_MD
              echo "ğŸ“Š **Summary**: $TOTAL_TESTS Tests | âœ… $PASSED_TESTS Passed | âŒ $FAILED_TESTS Failed" >> $AONE_CI_SUMMARY_MD
              echo "" >> $AONE_CI_SUMMARY_MD
              echo "### ğŸ“‹ å¤±è´¥æµ‹è¯•è¯¦æƒ…" >> $AONE_CI_SUMMARY_MD
              echo "" >> $AONE_CI_SUMMARY_MD
              
              # Process each failed test and create collapsible sections
              # Split the report by the separator and process each test individually
              awk '
              BEGIN { 
                RS = "---\n\nâŒ å¤±è´¥æµ‹è¯•\n";  # Record separator
                test_count = 0;
              }
              
              # Skip the first record (header content before first test)
              NR == 1 { next; }
              
              # Process each failed test record
              {
                test_count++;
                
                # Extract test ID from first line
                split($0, lines, "\n");
                test_id = "";
                content = "";
                
                for (i = 1; i <= length(lines); i++) {
                  if (lines[i] ~ /^æµ‹è¯•ID:/) {
                    gsub(/^æµ‹è¯•ID: /, "", lines[i]);
                    test_id = lines[i];
                  } else if (test_id != "" && lines[i] != "") {
                    content = content lines[i] "\n";
                  }
                }
                
                # Output the test with collapsible sections
                if (test_id != "") {
                  print "<details>";
                  print "<summary>" test_count ". " test_id "</summary>";
                  print "";
                  
                  # Parse content into sections
                  ai_analysis = "";
                  output_snippet = "";
                  fix_prompt = "";
                  current_section = "";
                  
                  split(content, content_lines, "\n");
                  for (j = 1; j <= length(content_lines); j++) {
                    line = content_lines[j];
                    
                    if (line ~ /^ğŸ¤– AI Analysis/) {
                      current_section = "ai_analysis";
                      continue;
                    } else if (line ~ /^ğŸ“„ Output/) {
                      current_section = "output_snippet";  
                      continue;
                    } else if (line ~ /^ğŸ› ï¸ AIä¿®å¤æç¤ºè¯/) {
                      current_section = "fix_prompt";
                      continue;
                    } else if (line ~ /^```/) {
                      continue;  # Skip code block markers
                    }
                    
                    if (current_section == "ai_analysis" && line != "") {
                      ai_analysis = ai_analysis line "\n";
                    } else if (current_section == "output_snippet" && line != "") {
                      output_snippet = output_snippet line "\n";
                    } else if (current_section == "fix_prompt" && line != "") {
                      fix_prompt = fix_prompt line "\n";
                    }
                  }
                  
                  # Output subsections
                  if (ai_analysis != "") {
                    print "<details>";
                    print "<summary>ğŸ¤– AIåˆ†æ</summary>";
                    print "";
                    print ai_analysis;
                    print "</details>";
                    print "";
                  }
                  
                  if (output_snippet != "") {
                    print "<details>";
                    print "<summary>ğŸ“„ æ—¥å¿—ç‰‡æ®µ</summary>";
                    print "";
                    print "```";
                    print output_snippet;
                    print "```";
                    print "</details>";
                    print "";
                  }
                  
                  if (fix_prompt != "") {
                    print "<details>";
                    print "<summary>ğŸ› ï¸ AIä¿®å¤æç¤ºè¯</summary>";
                    print "";
                    print "```";
                    print fix_prompt;
                    print "```";
                    print "</details>";
                    print "";
                  }
                  
                  print "</details>";
                  print "";
                }
              }
              ' test_report.md >> $AONE_CI_SUMMARY_MD
            fi
            
            # Archive as build artifacts
            mkdir -p artifacts
            cp test_report.md artifacts/smart_test_report.md
          else
            echo "âš ï¸ No test report generated"
            echo "## âŒ Smart Integration Test Report" >> $AONE_CI_SUMMARY_MD
            echo "No test report was generated. Check the logs above for errors." >> $AONE_CI_SUMMARY_MD
          fi
          else
            echo "âŒ Smart Test Runner failed with exit code $?"
            echo "âŒ CI pipeline will now fail"
            exit 1
          fi
          
      - id: display-test-results
        name: "Display Test Results"
        run: |
          if [ -f "test_report.md" ]; then
            echo "ğŸ“‹ å¤±è´¥æµ‹è¯•æ¦‚è§ˆï¼š"
            echo ""
            
            # Create individual collapsible sections for each failed test
            if grep -q "âŒ å¤±è´¥æµ‹è¯•" test_report.md; then
              # Process each failed test and create separate collapsible sections with sub-sections
              awk '
              BEGIN { 
                test_count = 0;
                in_test = 0;
                test_id = "";
                ai_analysis = "";
                output_snippet = "";
                fix_prompt = "";
                current_section = "";
              }
              
              /^âŒ å¤±è´¥æµ‹è¯•/ {
                # If we have a previous test, output it
                if (test_count > 0 && test_id != "") {
                  print "::group::" test_count ". " test_id;
                  
                  # AI Analysis subsection
                  if (ai_analysis != "") {
                    print "::group::ğŸ¤– AIåˆ†æ";
                    print ai_analysis;
                    print "::endgroup::";
                    print "";
                  }
                  
                  # Output snippet subsection
                  if (output_snippet != "") {
                    print "::group::ğŸ“„ æ—¥å¿—ç‰‡æ®µ";
                    print "```";
                    print output_snippet;
                    print "```";
                    print "::endgroup::";
                    print "";
                  }
                  
                  # Fix prompt subsection
                  if (fix_prompt != "") {
                    print "::group::ğŸ› ï¸ AIä¿®å¤æç¤ºè¯";
                    print "```";
                    print fix_prompt;
                    print "```";
                    print "::endgroup::";
                    print "";
                  }
                  
                  print "::endgroup::";
                  print "";
                }
                
                # Start new test
                test_count++;
                in_test = 1;
                test_id = "";
                ai_analysis = "";
                output_snippet = "";
                fix_prompt = "";
                current_section = "";
                
                # Read next line which should contain the test ID
                if (getline > 0 && /^æµ‹è¯•ID:/) {
                  # Extract test ID from "æµ‹è¯•ID: test_id_here"
                  gsub(/^æµ‹è¯•ID: /, "", $0);
                  test_id = $0;
                }
                next;
              }
              
              /^ğŸ¤– AI Analysis/ && in_test {
                current_section = "ai_analysis";
                next;
              }
              
              /^ğŸ“„ Output \(Snippet\)/ && in_test {
                current_section = "output_snippet";
                next;
              }
              
              /^ğŸ› ï¸ AIä¿®å¤æç¤ºè¯/ && in_test {
                current_section = "fix_prompt";
                next;
              }
              
              /^```/ && in_test {
                # Skip code block markers
                next;
              }
              
              /^---$/ && in_test {
                # End of current test section
                in_test = 0;
                current_section = "";
                next;
              }
              
              in_test && current_section == "ai_analysis" {
                ai_analysis = ai_analysis $0 "\n";
              }
              
              in_test && current_section == "output_snippet" {
                output_snippet = output_snippet $0 "\n";
              }
              
              in_test && current_section == "fix_prompt" {
                fix_prompt = fix_prompt $0 "\n";
              }
              
              END {
                # Output the last test if exists
                if (test_count > 0 && test_id != "") {
                  print "::group::" test_count ". " test_id;
                  
                  # AI Analysis subsection
                  if (ai_analysis != "") {
                    print "::group::ğŸ¤– AIåˆ†æ";
                    print ai_analysis;
                    print "::endgroup::";
                    print "";
                  }
                  
                  # Output snippet subsection
                  if (output_snippet != "") {
                    print "::group::ğŸ“„ æ—¥å¿—ç‰‡æ®µ";
                    print "```";
                    print output_snippet;
                    print "```";
                    print "::endgroup::";
                    print "";
                  }
                  
                  # Fix prompt subsection
                  if (fix_prompt != "") {
                    print "::group::ğŸ› ï¸ AIä¿®å¤æç¤ºè¯";
                    print "```";
                    print fix_prompt;
                    print "```";
                    print "::endgroup::";
                    print "";
                  }
                  
                  print "::endgroup::";
                }
              }
              ' test_report.md
              
            else
              echo "âœ… æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼"
            fi
            
            # Show success summary from the summary line
            if grep -q "Tests |" test_report.md; then
              SUMMARY_LINE=$(grep "Tests |" test_report.md | head -1)
              echo ""
              echo "ğŸ“Š $SUMMARY_LINE"
            fi
          else
            echo "âš ï¸ æµ‹è¯•æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨"
          fi

