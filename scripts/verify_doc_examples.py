import os
import sys
import argparse
import subprocess
import shutil
import time
import re
from typing import List, Dict, Any, Optional, TypedDict, Literal
import json

# Ensure we can import standard libraries.
print("ğŸ” æ­£åœ¨æ£€æŸ¥Pythonç¯å¢ƒå’Œä¾èµ–...")

# Check each import individually
try:
    from langchain_openai import ChatOpenAI
    print("âœ… langchain_openaiå¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ langchain_openaiå¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

try:
    from langgraph.graph import StateGraph, END
    print("âœ… langgraphå¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ langgraphå¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

try:
    from langchain_core.prompts import ChatPromptTemplate
    print("âœ… langchain_coreå¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ langchain_coreå¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

# Configuration
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if os.path.basename(PROJECT_ROOT) == "scripts": 
    PROJECT_ROOT = os.path.dirname(PROJECT_ROOT)

DOCS_DIRS = [
    os.path.join(PROJECT_ROOT, "python", "docs"),
    os.path.join(PROJECT_ROOT, "docs", "guides")
]
TMP_DIR = os.path.join(PROJECT_ROOT, "tmp", "doc_verification")
LLMS_FULL_PATH = os.path.join(PROJECT_ROOT, "llms-full.txt")
REPORT_FILE = os.path.join(PROJECT_ROOT, "tmp", "doc_verification_report.md")

# Ensure tmp dir exists
os.makedirs(TMP_DIR, exist_ok=True)

# State Definition
class Snippet(TypedDict):
    id: str
    file_path: str
    line_number: int
    content: str
    context: str # Surrounding text for context

class VerificationResult(TypedDict):
    snippet_id: str
    file_path: str
    status: str  # 'passed', 'failed_doc_issue', 'failed_gen_issue', 'skipped'
    output: str
    analysis: Optional[str]
    verification_code: Optional[str]

class AgentState(TypedDict):
    # Global
    snippet_queue: List[Snippet]
    current_index: int
    results: List[VerificationResult]
    sdk_context: str
    pattern: Optional[str]
    report_file: str
    
    # Per-snippet loop
    current_snippet: Optional[Snippet]
    verification_script: Optional[str]
    execution_output: Optional[str]
    execution_success: bool
    retry_count: int
    analysis: Optional[str]
    is_doc_issue: bool
    skip_reason: Optional[str]

# --- Helper Functions ---

def get_model():
    """Initializes the Qwen model via ChatOpenAI interface."""
    api_key = os.environ.get("DASHSCOPE_API_KEY")
    if not api_key:
        print("âš ï¸ æœªæ‰¾åˆ°DASHSCOPE_API_KEYï¼Œæ— æ³•ä½¿ç”¨AIåŠŸèƒ½ã€‚")
        return None
    
    return ChatOpenAI(
        model="qwen-max", 
        openai_api_key=api_key,
        openai_api_base="https://dashscope.aliyuncs.com/compatible-mode/v1",
        temperature=0.1
    )

def load_sdk_context():
    if os.path.exists(LLMS_FULL_PATH):
        try:
            with open(LLMS_FULL_PATH, "r", encoding="utf-8") as f:
                return f.read()
        except Exception as e:
            print(f"âš ï¸ è¯»å–llms-full.txtå¤±è´¥: {e}")
    return ""

def extract_snippets_from_md(file_path: str) -> List[Snippet]:
    snippets = []
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            lines = f.readlines()
            
        in_code_block = False
        code_lines = []
        start_line = 0
        lang = ""
        
        # Simple parser for ```python blocks
        for i, line in enumerate(lines):
            stripped = line.strip()
            if stripped.startswith("```"):
                if in_code_block:
                    # End of block
                    in_code_block = False
                    if lang in ["python", "py"]:
                        content = "".join(code_lines)
                        if content.strip(): # Ignore empty blocks
                            # Get some context (previous 5 lines)
                            context_start = max(0, start_line - 5)
                            context = "".join(lines[context_start:start_line])
                            
                            snippets.append({
                                "id": f"{os.path.basename(file_path)}:{start_line}",
                                "file_path": os.path.relpath(file_path, PROJECT_ROOT),
                                "line_number": start_line + 1,
                                "content": content,
                                "context": context
                            })
                    code_lines = []
                    lang = ""
                else:
                    # Start of block
                    lang = stripped.lstrip("`").strip().lower()
                    if lang in ["python", "py"]:
                        in_code_block = True
                        start_line = i
            elif in_code_block:
                code_lines.append(line)
                
    except Exception as e:
        print(f"âš ï¸ è§£ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
    return snippets

# --- Nodes ---

def discover_examples(state: AgentState) -> AgentState:
    """Finds all python code blocks in markdown files."""
    print(f"ğŸ” æ­£åœ¨æ‰«ææ–‡æ¡£ç›®å½•...")
    all_snippets = []
    
    for doc_dir in DOCS_DIRS:
        if not os.path.exists(doc_dir):
            continue
            
        for root, _, files in os.walk(doc_dir):
            for file in files:
                if file.endswith(".md"):
                    full_path = os.path.join(root, file)
                    snippets = extract_snippets_from_md(full_path)
                    all_snippets.extend(snippets)
    
    # Filter based on pattern if provided
    if state.get("pattern"):
        pattern = state["pattern"]
        all_snippets = [s for s in all_snippets if pattern in s["file_path"]]
        print(f"ğŸ” åº”ç”¨è¿‡æ»¤æ¨¡å¼ '{pattern}': å‰©ä½™ {len(all_snippets)} ä¸ªä»£ç ç‰‡æ®µ")
    
    print(f"âœ… æ€»å…±æ‰¾åˆ° {len(all_snippets)} ä¸ªPythonä»£ç ç‰‡æ®µã€‚")
    
    return {
        **state,
        "snippet_queue": all_snippets,
        "current_index": 0,
        "sdk_context": load_sdk_context()
    }

def prepare_snippet(state: AgentState) -> AgentState:
    """Loads the current snippet."""
    idx = state["current_index"]
    if idx >= len(state["snippet_queue"]):
        return state
    
    snippet = state["snippet_queue"][idx]
    print(f"ğŸ“– å¤„ç†ç‰‡æ®µ ({idx+1}/{len(state['snippet_queue'])}): {snippet['id']}")
    
    return {
        **state,
        "current_snippet": snippet,
        "verification_script": None,
        "execution_output": None,
        "execution_success": False,
        "retry_count": 0,
        "analysis": None,
        "is_doc_issue": False,
        "skip_reason": None
    }

def generate_verification_script(state: AgentState) -> AgentState:
    """Generates a verification script using LLM, or decides to skip."""
    snippet = state["current_snippet"]
    retry_count = state["retry_count"]
    analysis = state["analysis"]
    
    print(f"ğŸ¤– æ­£åœ¨åˆ†æ/ç”ŸæˆéªŒè¯è„šæœ¬ (å°è¯• {retry_count+1})...")
    
    model = get_model()
    if not model:
        return {**state, "skip_reason": "No AI model available"}

    # Simplify context
    sdk_context_snippet = state["sdk_context"][:20000] + "..." if len(state["sdk_context"]) > 20000 else state["sdk_context"]

    prompt_template = """
ä½ æ˜¯ä¸€ä¸ªPython SDKä¸“å®¶ã€‚ä½ éœ€è¦éªŒè¯æ–‡æ¡£ä¸­çš„Pythonä»£ç ç‰‡æ®µã€‚

### SDK Context
{sdk_context}

### æ–‡æ¡£æ–‡ä»¶: {file_path}
### ä¸Šä¸‹æ–‡:
{context}

### ä»£ç ç‰‡æ®µ:
```python
{code_content}
```

### ä»»åŠ¡
1. **ä¸¥æ ¼åˆ¤æ–­**è¯¥ä»£ç ç‰‡æ®µæ˜¯å¦æ˜¯**å¯è¿è¡Œçš„ç¤ºä¾‹ä»£ç ** (Usage Example)ã€‚
   - **å¿…é¡»è·³è¿‡**: å‡½æ•°ç­¾å (å¦‚ `def func(...)`)ã€ç±»å®šä¹‰ (å¦‚ `class MyClass`)ã€APIæ¥å£æè¿°ã€ä»…æœ‰å˜é‡å£°æ˜ä½†æ— ä¸Šä¸‹æ–‡çš„ä»£ç ã€‚
   - **å¿…é¡»è·³è¿‡**: ä»…åŒ…å« `pip install` æˆ–éPythonä»£ç ã€‚
   - **å¯ä»¥ç”Ÿæˆ**: åŒ…å«å…·ä½“é€»è¾‘ã€å‡½æ•°è°ƒç”¨ã€`print`è¯­å¥ã€`await`æ“ä½œçš„ç¤ºä¾‹ä»£ç ã€‚

2. **å¦‚æœå†³å®šéªŒè¯ (GENERATE)**:
   - ç¼–å†™ä¸€ä¸ªå®Œæ•´çš„ã€å¯æ‰§è¡Œçš„Pythonè„šæœ¬ã€‚
   - è¡¥å…¨ `import os`, `import asyncio`, `from agentbay import ...` ç­‰ã€‚
   - åˆå§‹åŒ–å¿…è¦çš„å®¢æˆ·ç«¯ (å¦‚ `AsyncAgentBay(api_key=os.getenv("AGENTBAY_API_KEY"))`)ã€‚
   - å‡è®¾ `AGENTBAY_API_KEY` ç¯å¢ƒå˜é‡å·²å­˜åœ¨ã€‚
   - å°†é€»è¾‘åŒ…è£¹åœ¨ `async def main():` ä¸­å¹¶è¿è¡Œ `asyncio.run(main())`ã€‚
   - å¦‚æœç¤ºä¾‹ä¸­ä½¿ç”¨äº†æœªå®šä¹‰çš„å˜é‡ (å¦‚ `session_id`)ï¼Œè¯·**åŠ¡å¿…**åœ¨è„šæœ¬ä¸­å…ˆåˆ›å»ºç›¸åº”çš„èµ„æºè·å–è¯¥IDï¼Œæˆ–è€…mockå®ƒã€‚ä¸è¦ç›´æ¥ä½¿ç”¨æœªå®šä¹‰çš„å˜é‡ã€‚

{retry_instruction}

### è¾“å‡ºæ ¼å¼
å¦‚æœè·³è¿‡:
SKIP: <è·³è¿‡åŸå› >

å¦‚æœç”Ÿæˆè„šæœ¬:
```python
<å®Œæ•´è„šæœ¬å†…å®¹>
```
"""
    
    retry_instruction = ""
    if retry_count > 0 and analysis:
        retry_instruction = f"""
        ### ä¸Šæ¬¡éªŒè¯å¤±è´¥
        ä¸Šæ¬¡ç”Ÿæˆçš„è„šæœ¬æ‰§è¡Œå¤±è´¥ã€‚
        é”™è¯¯åˆ†æ: {analysis}
        
        è¯·æ ¹æ®åˆ†æä¿®å¤éªŒè¯è„šæœ¬ã€‚
        """

    prompt = ChatPromptTemplate.from_template(prompt_template)
    
    try:
        chain = prompt | model
        response = chain.invoke({
            "sdk_context": sdk_context_snippet,
            "file_path": snippet["file_path"],
            "context": snippet["context"],
            "code_content": snippet["content"],
            "retry_instruction": retry_instruction
        })
        
        text = response.content.strip()
        
        if text.startswith("SKIP:"):
            reason = text.split("SKIP:", 1)[1].strip()
            print(f"   â© è·³è¿‡: {reason}")
            return {**state, "skip_reason": reason, "verification_script": None}
            
        if "```python" in text:
            script = text.split("```python")[1].split("```")[0].strip()
        elif "```" in text:
            script = text.split("```")[1].split("```")[0].strip()
        else:
            script = text
            
        # Fallback if model returns code but no SKIP and no ``` block (rare)
        if not script and "SKIP" not in text: 
             script = text

        return {**state, "verification_script": script, "skip_reason": None}
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆè„šæœ¬å¤±è´¥: {e}")
        return {**state, "skip_reason": f"AI Generation Failed: {e}", "verification_script": None}

def execute_script(state: AgentState) -> AgentState:
    """Executes the verification script."""
    if state["skip_reason"]:
        return state
        
    script = state["verification_script"]
    
    # Prepare temp dir
    run_dir = os.path.join(TMP_DIR, f"run_{state['current_index']}")
    if os.path.exists(run_dir):
        shutil.rmtree(run_dir)
    os.makedirs(run_dir)
    
    script_path = os.path.join(run_dir, "verify_snippet.py")
    with open(script_path, "w", encoding="utf-8") as f:
        f.write(script)
        
    print(f"â–¶ï¸ æ‰§è¡ŒéªŒè¯è„šæœ¬...")
    
    env = os.environ.copy()
    env["PYTHONPATH"] = os.path.join(PROJECT_ROOT, "python") + os.pathsep + env.get("PYTHONPATH", "")
    
    try:
        result = subprocess.run(
            [sys.executable, "verify_snippet.py"],
            cwd=run_dir,
            capture_output=True,
            text=True,
            env=env,
            timeout=120 # 2 mins timeout
        )
        
        success = (result.returncode == 0)
        output = result.stdout + "\n" + result.stderr
        
        print(f"   ç»“æœ: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")
        
        return {
            **state,
            "execution_output": output,
            "execution_success": success
        }
        
    except subprocess.TimeoutExpired:
        print("   ç»“æœ: âŒ è¶…æ—¶")
        return {
            **state,
            "execution_output": "Execution timed out after 120s",
            "execution_success": False
        }
    except Exception as e:
        print(f"   ç»“æœ: âŒ æ‰§è¡Œå¼‚å¸¸ {e}")
        return {
            **state,
            "execution_output": str(e),
            "execution_success": False
        }

def analyze_failure(state: AgentState) -> AgentState:
    """Analyzes failure."""
    output = state["execution_output"]
    script = state["verification_script"]
    snippet = state["current_snippet"]
    
    print("ğŸ¤– åˆ†æå¤±è´¥åŸå› ...")
    
    model = get_model()
    if not model:
        return {**state, "analysis": "No AI model", "is_doc_issue": True}
        
    prompt = ChatPromptTemplate.from_template("""
ä½ æ˜¯ä¸€ä¸ªPythonä¸“å®¶ã€‚æˆ‘æ­£åœ¨éªŒè¯æ–‡æ¡£ä¸­çš„ä»£ç ç‰‡æ®µã€‚

### åŸå§‹æ–‡æ¡£ç‰‡æ®µ:
```python
{code_content}
```

### ç”Ÿæˆçš„éªŒè¯è„šæœ¬:
```python
{script}
```

### æ‰§è¡Œè¾“å‡º:
{output}

### ä»»åŠ¡
åˆ†æå¤±è´¥åŸå› ã€‚åˆ¤æ–­æ˜¯ï¼š
1. **ç”Ÿæˆä»£ç é—®é¢˜**: éªŒè¯è„šæœ¬åŒ…è£…æœ‰é—®é¢˜ï¼ˆå¦‚mockä¸å¯¹ã€ç¯å¢ƒç¼ºå¤±ã€é€»è¾‘é”™è¯¯ï¼‰ã€‚
2. **æ–‡æ¡£ä»£ç é—®é¢˜**: åŸå§‹æ–‡æ¡£ç‰‡æ®µæœ¬èº«æœ‰é”™ï¼ˆAPIä¸å­˜åœ¨ã€å‚æ•°é”™è¯¯ã€é€»è¾‘ä¸é€šï¼‰ã€‚

è¯·è¿”å›ä¸¥æ ¼çš„JSONæ ¼å¼ï¼Œä¸è¦åŒ…å«Markdownä»£ç å—æ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰ï¼Œä¹Ÿä¸è¦åŒ…å«ä»»ä½•æ³¨é‡Šã€‚
{{
    "reason": "ç®€çŸ­åˆ†æ",
    "type": "gen_issue" æˆ– "doc_issue",
    "suggestion": "ä¿®å¤å»ºè®®"
}}
""")

    try:
        chain = prompt | model
        response = chain.invoke({
            "code_content": snippet["content"],
            "script": script,
            "output": output[-5000:]
        })
        
        content = response.content.strip()
        # Clean up markdown if present
        if content.startswith("```"):
            content = content.split("\n", 1)[1]
            if content.endswith("```"):
                content = content.rsplit("\n", 1)[0]
        
        # Try to find JSON block
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            content = json_match.group(0)
            
        try:
            analysis_json = json.loads(content)
        except json.JSONDecodeError:
            # Try to fix common JSON errors if simple load fails
            # e.g. single quotes to double quotes, though dangerous
            try:
                import ast
                analysis_json = ast.literal_eval(content)
            except:
                raise Exception(f"Failed to parse JSON: {content[:100]}...")
        
        is_doc_issue = (analysis_json.get("type") == "doc_issue")
        analysis_text = f"Type: {analysis_json.get('type')}\nReason: {analysis_json.get('reason')}\nSuggestion: {analysis_json.get('suggestion')}"
        
        print(f"   åˆ†æç»“æœ: {'ğŸ“„ æ–‡æ¡£é—®é¢˜' if is_doc_issue else 'ğŸ› ï¸ ç”Ÿæˆè„šæœ¬é—®é¢˜'}")
        
        return {
            **state,
            "analysis": analysis_text,
            "is_doc_issue": is_doc_issue
        }
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return {
            **state,
            "analysis": f"Analysis failed: {e}",
            "is_doc_issue": True 
        }

def record_result(state: AgentState) -> AgentState:
    """Records the result."""
    snippet = state["current_snippet"]
    
    if state["skip_reason"]:
        status = "skipped"
        output = state["skip_reason"]
        analysis = None
    elif state["execution_success"]:
        status = "passed"
        output = state["execution_output"]
        analysis = None
    else:
        status = "failed_doc_issue" if state["is_doc_issue"] else "failed_gen_issue"
        output = state["execution_output"]
        analysis = state["analysis"]
        
    result: VerificationResult = {
        "snippet_id": snippet["id"],
        "file_path": snippet["file_path"],
        "status": status,
        "output": output,
        "analysis": analysis,
        "verification_code": state.get("verification_script")
    }
    
    new_results = state["results"] + [result]
    
    return {
        **state,
        "results": new_results,
        "current_index": state["current_index"] + 1
    }

def generate_final_report(state: AgentState) -> AgentState:
    """Generates the final markdown report."""
    results = state["results"]
    passed = len([r for r in results if r["status"] == "passed"])
    # Only consider doc issues as failures for the final report to user
    failed_doc = len([r for r in results if r["status"] == "failed_doc_issue"])
    failed_gen = len([r for r in results if r["status"] == "failed_gen_issue"])
    skipped = len([r for r in results if r["status"] == "skipped"])
    
    content = f"# Smart Integration Test Report (Doc Verification)\n\n"
    content += f"**Summary**: {len(results)} Snippets | âœ… {passed} Passed | âŒ {failed_doc} Doc Issues | âš ï¸ {failed_gen} Script Issues | â­ï¸ {skipped} Skipped\n\n"
    
    if failed_doc == 0 and failed_gen == 0:
        content += "ğŸ‰ **All verifiable examples passed!**\n\n"
    
    if failed_doc > 0:
        content += f"## ğŸš¨ Documentation Issues ({failed_doc})\n\n"
        content += "è¿™äº›æ˜¯æ–‡æ¡£ä¸­å®é™…å­˜åœ¨çš„ä»£ç é”™è¯¯ï¼Œéœ€è¦ä¿®å¤ã€‚\n\n"
        
        for r in results:
            if r["status"] == "failed_doc_issue":
                content += f"---\n\n"
                content += f"### ğŸ“„ æ–‡ä»¶: `{r['file_path']}`\n"
                content += f"**ä½ç½®**: Line {r['snippet_id'].split(':')[1]}\n\n"
                
                content += "**é”™è¯¯åˆ†æ**:\n"
                if r.get('analysis'):
                    # Extract reason and suggestion from analysis text
                    analysis_text = r['analysis']
                    reason = ""
                    suggestion = ""
                    for line in analysis_text.split('\n'):
                        if line.startswith("Reason:"):
                            reason = line.replace("Reason:", "").strip()
                        elif line.startswith("Suggestion:"):
                            suggestion = line.replace("Suggestion:", "").strip()
                    
                    if reason:
                        content += f"- ğŸ”´ **åŸå› **: {reason}\n"
                    if suggestion:
                        content += f"- ğŸ’¡ **å»ºè®®**: {suggestion}\n"
                    if not reason and not suggestion:
                        content += f"{analysis_text}\n"
                else:
                    content += "æœªè¿›è¡ŒAIåˆ†æ\n"
                content += "\n"
                
                # Show execution output if relevant (e.g. SyntaxError from original code)
                # But filter out the verification script path noise
                output = r['output']
                if output:
                    clean_output = output
                    # Simple heuristic to clean up traceback paths
                    clean_output = re.sub(r'File ".*verify_snippet.py",', 'File "<generated_script>",', clean_output)
                    
                    content += "**æ‰§è¡ŒæŠ¥é”™**:\n"
                    content += f"```text\n{clean_output[-1000:]}\n```\n\n"

    if failed_gen > 0:
        content += f"## âš ï¸ Script Generation Issues ({failed_gen})\n\n"
        content += "è¿™äº›æ˜¯ç”ŸæˆéªŒè¯è„šæœ¬æ—¶çš„é—®é¢˜ï¼ˆå¯èƒ½æ˜¯ç¯å¢ƒã€mockæˆ–AIç”Ÿæˆé—®é¢˜ï¼‰ï¼Œ**ä¸ä»£è¡¨æ–‡æ¡£ä¸€å®šæœ‰é”™**ï¼Œä½†å»ºè®®äººå·¥æ£€æŸ¥ã€‚\n\n"
        
        for r in results:
            if r["status"] == "failed_gen_issue":
                content += f"- `{r['file_path']}` (Line {r['snippet_id'].split(':')[1]}) - "
                if r.get('analysis'):
                     for line in r['analysis'].split('\n'):
                        if line.startswith("Reason:"):
                            content += f"{line.replace('Reason:', '').strip()}\n"
                            break
                else:
                     content += "Unknown error\n"

    report_file = state.get("report_file", REPORT_FILE)
    try:
        with open(report_file, "w", encoding="utf-8") as f:
            f.write(content)
        print(f"ğŸ“ æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
    except Exception as e:
        print(f"âŒ å†™å…¥æŠ¥å‘Šå¤±è´¥: {e}")
        
    return state

def increment_retry(state: AgentState) -> AgentState:
    """Increments the retry count."""
    return {**state, "retry_count": state["retry_count"] + 1}

# --- Routing ---

def check_script_generation(state: AgentState):
    if state["skip_reason"]:
        return "record_result"
    return "execute_script"

def check_execution(state: AgentState):
    if state["execution_success"]:
        return "record_result"
    return "analyze_failure"

def check_retry_condition(state: AgentState):
    if state["is_doc_issue"]:
        return "record_result"
    
    if state["retry_count"] < 2: # Max 2 retries
        return "increment_retry"
    
    return "record_result"

def check_loop(state: AgentState):
    if state["current_index"] < len(state["snippet_queue"]):
        return "prepare_snippet"
    return "generate_final_report"

# --- Graph Construction ---

workflow = StateGraph(AgentState)

workflow.add_node("discover_examples", discover_examples)
workflow.add_node("prepare_snippet", prepare_snippet)
workflow.add_node("generate_verification_script", generate_verification_script)
workflow.add_node("execute_script", execute_script)
workflow.add_node("analyze_failure", analyze_failure)
workflow.add_node("increment_retry", increment_retry)
workflow.add_node("record_result", record_result)
workflow.add_node("generate_final_report", generate_final_report)

workflow.set_entry_point("discover_examples")

workflow.add_edge("discover_examples", "prepare_snippet")
workflow.add_edge("prepare_snippet", "generate_verification_script")
workflow.add_edge("increment_retry", "generate_verification_script")

workflow.add_conditional_edges(
    "generate_verification_script",
    check_script_generation,
    {
        "record_result": "record_result",
        "execute_script": "execute_script"
    }
)

workflow.add_conditional_edges(
    "execute_script",
    check_execution,
    {
        "record_result": "record_result",
        "analyze_failure": "analyze_failure"
    }
)

workflow.add_conditional_edges(
    "analyze_failure",
    check_retry_condition,
    {
        "increment_retry": "increment_retry",
        "record_result": "record_result"
    }
)

workflow.add_conditional_edges(
    "record_result",
    check_loop,
    {
        "prepare_snippet": "prepare_snippet",
        "generate_final_report": "generate_final_report"
    }
)

workflow.add_edge("generate_final_report", END)

app = workflow.compile()

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--limit", type=int, help="Limit number of examples to verify", default=None)
    parser.add_argument("--pattern", type=str, help="Filter files by pattern", default=None)
    parser.add_argument("--report", type=str, help="Report file path", default=REPORT_FILE)
    args = parser.parse_args()
    
    initial_state = {
        "snippet_queue": [],
        "current_index": 0,
        "results": [],
        "sdk_context": "",
        "pattern": args.pattern,
        "report_file": args.report,
        "current_snippet": None,
        "verification_script": None,
        "execution_output": None,
        "execution_success": False,
        "retry_count": 0,
        "analysis": None,
        "is_doc_issue": False,
        "skip_reason": None
    }
    
    try:
        # Increase recursion limit for long loops
        config = {"recursion_limit": 10000}
        app.invoke(initial_state, config=config)
    except Exception as e:
        print(f"ğŸ’¥ æ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
